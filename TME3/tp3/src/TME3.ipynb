{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gérer les données avec *Dataset* et *Dataloader*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `Dataset` et `Dataloader` permettent de faciliter la gestion des données sous `PyTorch`. \n",
    "\n",
    "La classe `Dataset` est une classe abstraite qui permet de préciser comment un exemple est chargé, pré-traité, transformé ... et donne accès par l'intermédiaire d'un itérateur à chaque exemple d'un jeu de donnnées. \n",
    "\n",
    "La classe `Dataloader` encapsule un jeu de données et permet de requêter de diverses manières ce jeu de données: spécifier la taille du mini-batch, si l'ordre doit être aléatoire ou non, de quelle manière sont concaténés les exemples etc... Combines a dataset and a sampler and provides an iterable over the given dataset\n",
    "\n",
    "Pour implémenter un `Dataset`, il suffit de définit 2 méthodes `__getitem__(self, index)` et `__len(self)`:\n",
    "\n",
    "`from torch.utils.data import Dataset, DataLoader`\n",
    "\n",
    "`class MonDataset(Dataset):`\n",
    "\n",
    "    `def __init__(self, ...):`\n",
    "\n",
    "        `pass`\n",
    "\n",
    "    `def __getitem__(self, index):`\n",
    "\n",
    "    retourne un couple (exemple, label) correspondant à l'index\n",
    "        \n",
    "        `pass`\n",
    "    \n",
    "    `def __len__(self):`\n",
    "\n",
    "    renvoie la taille du jeu de données\n",
    "    \n",
    "        `pass`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principaux avantages (mis à part le prétraitement possible) est qu'il n'est pas nécessaire de charger tout le jeu de données en mémoire, le chargement se fait à la volée. Par ailleurs, la classe pré-existante `TensorDataset` permet de construire un dataset pour une liste de tenseurs passée en argument (le ième exemple est un nuplet composé de la ième ligne de chaque tenseur)\n",
    "\n",
    "Une fois `MonDataset` implémenté il suffit de créer un `DataLoader` de la manière suivante :\n",
    "\n",
    "`data = DataLoader(MonDataset(...), shuffle = True, batch_size = BATCH_SIZE)`\n",
    "\n",
    "création du dataloader en spécifiant la taille du batch et ordre aléatoire\n",
    "\n",
    "`for x, y in data:`\n",
    "\n",
    "    x et y est un batch de taille BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je veux implémenter un dataset pour le jeu de données MNIST qui renvoie une image sous la forme d'un vecteur normalisé entre 0 et 1 et le label associé (sans utiliser `TensorDataset`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de profiter de la puissance de calcul d'un GPU, il faut obligatoirement spécifier à `PyTorch` de charger les tenseurs sur le GPU ainsi que le module (i.e. les paramètres du module). Il n'est pas possible de faire des opérations lorsqu'une partie des tenseurs est sur GPU et l'autre sur CPU (un message d'erreur s'affiche). L'opérateur `to(device)` des tenseurs et des modules permet de les copier sur le GPU (ou CPU) spécifié. Attention l'opération n'est pas *inplace*, il faut sauver le résultat dans une variable qui elle sera sur le bon device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Permet de sélectionner le gpu si disponible*\n",
    "\n",
    "`device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')`\n",
    "\n",
    "`model = ...`\n",
    "\n",
    "`model = model.to(device)` *chargement du module sur device*\n",
    "\n",
    "`x = x.to(device)` *charge données sur device*\n",
    "\n",
    "`y = model(x)` *calcul gpu\n",
    "\n",
    "`y = y.to(device = 'cpu)` *si on veut remettre sur cpu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
