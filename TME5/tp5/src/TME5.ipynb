{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAL TP5\n",
    "## Réseaux récurrents LSTM, GRU, autres cellules de mémoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment traiter et générer des séquences de taille variable?*\n",
    "\n",
    "*Comment prendre en compte des dépendances à plus long terme (Vanishing, exploding, gradients)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Générations de séquences de taille variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous considérons que chaque séquence est une phrase (qui peut se terminer par un point, un point d'interrogation ou un point d'exclamation).\n",
    "\n",
    "Dès lors il faut:\n",
    "- employer un symbole spécial qui marque la fin d'une séquence EOS. Lors de l'apprentissage, il faut ajouter ce token à chaque séquence pour apprendre à le prédire.\n",
    "- padder chaque séquence (ajouter un caractère nul (BLANK) autant de fois qu'il est nécessaire afin que les séquences d'un même batch aient toutes la même longueur, ce caractère devra être ignoré lors de l'apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1.\n",
    "Dans `testloader.py` la classe `TextDataset` est telle que:\n",
    "- chaque exemple est une phrase\n",
    "- la taille du dataset est le nbr de phrases ds le corpus\n",
    "- la phrase renvoyée est sous forme d'une séquence d'entiers, chaque entier codant pr un caractère (application de la fonciton `string2code`)\n",
    "Cette classe renvoie des exemples de longueur variable. Il faut préciser au DataLoader de quelle manière regrouper les exemples pr construire un batch. C'est le rôle de l'argument `collate_fn` du constructeur d'un DataLoader qui prend une fonction en paramètre.\n",
    "Définir une fonction `pad_collate_fn` qui prépare un tenseur batch (de taille `longueur x taille du batch` où la longueur = longeur max de la séquence du batch) à partir d'une liste d'exemples du `TextDataset`: elle doit ajouter le code du symbole EOS à la fin de chaque exemple et padder les séquences avec le code du caractère nul. Exécuter `textloader.py`pr vérifier que tout foncitonne bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, il faut prendre soin de ne pas inclure le padding lorsqu’on calcule le coût ici le maximum de vraisemblance : pour cela, la solution la plus courante est d’utiliser un masque binaire (0 lorsque le caractère est nul, 1 sinon) qui est  multiplié avec les log-probabilités avant\n",
    "de les additionner (le paramètre `reduce=\"none\"` dans une fonction de coût\n",
    "(en particulier, pour la cross entropie) permet d’obtenir le coût pour chaque élément plutôt que la moyenne).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaîne à code :  C'est. Un. Test.\n",
      "Shape ok\n",
      "encodage OK\n",
      "Token EOS ok\n",
      "Token BLANK ok\n",
      "Chaîne décodée :  C'est. Un. Test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nolwenn/AMAL/TME5/tp5/src/textloader.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%run textloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.\n",
    "\n",
    "Créer votre fonction de coût `maskedCrossEntropy(output, target, padcar) ` dans `tp5.py` qui permet de calculer le coût sans prendre en compte les caracètres nuls en\n",
    "fonction de la sortie obtenue output, la sortie désirée target et le code de caractère\n",
    "de padding padcar. Vous ferez attention à n’utiliser aucune boucle pour ce calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from textloader import *\n",
    "from generate import *\n",
    "import torch.nn.functional\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedCrossEntropy(output: torch.Tensor, target: torch.LongTensor, padcar: int):\n",
    "    \"\"\"\n",
    "    :param output: Tenseur length x batch x output_dim,\n",
    "    :param target: Tenseur length x batch\n",
    "    :param padcar: index du caractere de padding\n",
    "    \"\"\"\n",
    "    #  TODO:  Implémenter maskedCrossEntropy sans aucune boucle, la CrossEntropy qui ne prend pas en compte les caractères de padding.\n",
    "\n",
    "    # Reshape output and target tensors\n",
    "    output = output.view(-1, output.size(-1))\n",
    "    target = target.view(-1)\n",
    "\n",
    "    # Calcul du coût cross-entropique\n",
    "    ce_loss = torch.nn.CrossEntropyLoss(reduction = 'none')\n",
    "    loss = ce_loss(output, target)\n",
    "    \n",
    "    # Créer un masque en utilisant le caractère de padding, marking non-padding positions with 1.0 and padding positions with 0.0.\n",
    "    mask = torch.where(target == padcar, 0, 1)\n",
    "    \n",
    "    return torch.sum(loss[mask]) / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.161106586456299\n"
     ]
    }
   ],
   "source": [
    "# Dummy data\n",
    "output_dim = 10\n",
    "length = 5\n",
    "batch_size = 3\n",
    "padcar = 0\n",
    "\n",
    "# Randomly generated tensors for output and target\n",
    "output = torch.rand(length, batch_size, output_dim)\n",
    "target = torch.randint(0, output_dim, (length, batch_size), dtype=torch.long)\n",
    "\n",
    "# Call maskedCrossEntropy\n",
    "loss = maskedCrossEntropy(output, target, padcar)\n",
    "\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (embedding): Embedding(97, 64)\n",
       "  (rnn): RNN(64, 64, batch_first=True)\n",
       "  (linear_out): Linear(in_features=64, out_features=98, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tp5 import *\n",
    "input_dim = len(lettre2id)  # Adjust based on your data\n",
    "latent_dim = 64  # Adjust based on your preference\n",
    "output_dim = len(lettre2id) + 1  # Adjust based on your data\n",
    "model = SimpleRNN(input_dim, latent_dim, output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. \n",
    "Dans `generate.py` implémenter une fonction de génération de façon à générer des séquences jusqu'à rencontrer le caractère EOS (penser à prévoir une taille maximum tout de même). Prévoir de faire de la génération aléatoire dans la distribution obtenue ou déterministe en choisissant le caractère le plus probable à chaque pas de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>iGonQLWh**AGXD*P&oz<EOS>\n",
      "iGonQLWh**AGXD*P&oz\n"
     ]
    }
   ],
   "source": [
    "from generate import *\n",
    "# Test de generate\n",
    "\n",
    "generated_sequence = generate_sequence(model, initial_input=\"<START>\", eos_token=\"<EOS>\", device='cpu')\n",
    "print(generated_sequence)\n",
    "cleaned_sequence = generated_sequence.replace(\"<START>\", \"\").replace(\"<PAD>\", \"\").replace(\"<EOS>\", \"\")\n",
    "print(cleaned_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Beam Sequence: <START>NIr#Fe&gFpdyDFeFpdyDxs%TB<PAD>N!&VGe&gFpdFu(SYQMVfozb)n$u(o$us!&nSUGXhEHZ<PAD>NyF<PAD>m*CFu(!ags<PAD>&VXUT)!)n)pG*\"F\n"
     ]
    }
   ],
   "source": [
    "# Test de generate_beam\n",
    "generated_beam_sequence = generate_beam(model, initial_input=\"<START>\", eos_token=\"<EOS>\", k=3, device='cpu')\n",
    "\n",
    "print(\"Generated Beam Sequence:\", generated_beam_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleus Sampling Probabilities: tensor([[0.0000, 0.0000, 0.0231, 0.0108, 0.0203, 0.0109, 0.0145, 0.0148, 0.0000,\n",
      "         0.0105, 0.0096, 0.0000, 0.0000, 0.0153, 0.0000, 0.0237, 0.0202, 0.0111,\n",
      "         0.0103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0094, 0.0097, 0.0190, 0.0183, 0.0000, 0.0107, 0.0098,\n",
      "         0.0000, 0.0118, 0.0000, 0.0105, 0.0000, 0.0226, 0.0000, 0.0436, 0.0000,\n",
      "         0.0103, 0.0000, 0.0000, 0.0184, 0.0137, 0.0000, 0.0000, 0.0000, 0.0157,\n",
      "         0.0181, 0.0000, 0.0000, 0.0200, 0.0000, 0.0000, 0.0000, 0.0085, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0147, 0.0000, 0.0000, 0.0119, 0.0000, 0.0000,\n",
      "         0.0243, 0.0000, 0.0095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0201, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0145, 0.0149, 0.0000, 0.0180, 0.0205, 0.0000,\n",
      "         0.0127, 0.0122, 0.0144, 0.0000, 0.0189, 0.0116, 0.0000, 0.0098]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model instance is called 'model'\n",
    "alpha_value = 0.7\n",
    "nucleus_function = p_nucleus(model.linear_out, alpha_value)\n",
    "\n",
    "# Example state tensor (replace with your actual state tensor)\n",
    "example_state = torch.randn(1, model.rnn.hidden_size)\n",
    "\n",
    "nucleus_probs = nucleus_function(example_state)\n",
    "print(\"Nucleus Sampling Probabilities:\", nucleus_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de TP4, on a utilisé un encodage onehot pr chaque caractère, suivi d'un module linéaire. Le module `nn.Embedding` de `Torch` permet de combiner ces 2 étapes pr éviter la création (non nécessaire et coûteuse) de vecteurs one hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prise en compte de dépendences lointaines: LSTM et GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
